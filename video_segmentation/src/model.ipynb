{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torchsummary import summary\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 64, 107, 107]           9,408\n       BatchNorm2d-2         [-1, 64, 107, 107]             128\n              ReLU-3         [-1, 64, 107, 107]               0\n         MaxPool2d-4           [-1, 64, 54, 54]               0\n            Conv2d-5           [-1, 64, 54, 54]          36,864\n       BatchNorm2d-6           [-1, 64, 54, 54]             128\n              ReLU-7           [-1, 64, 54, 54]               0\n            Conv2d-8           [-1, 64, 54, 54]          36,864\n       BatchNorm2d-9           [-1, 64, 54, 54]             128\n             ReLU-10           [-1, 64, 54, 54]               0\n       BasicBlock-11           [-1, 64, 54, 54]               0\n           Conv2d-12           [-1, 64, 54, 54]          36,864\n      BatchNorm2d-13           [-1, 64, 54, 54]             128\n             ReLU-14           [-1, 64, 54, 54]               0\n           Conv2d-15           [-1, 64, 54, 54]          36,864\n      BatchNorm2d-16           [-1, 64, 54, 54]             128\n             ReLU-17           [-1, 64, 54, 54]               0\n       BasicBlock-18           [-1, 64, 54, 54]               0\n           Conv2d-19          [-1, 128, 27, 27]          73,728\n      BatchNorm2d-20          [-1, 128, 27, 27]             256\n             ReLU-21          [-1, 128, 27, 27]               0\n           Conv2d-22          [-1, 128, 27, 27]         147,456\n      BatchNorm2d-23          [-1, 128, 27, 27]             256\n           Conv2d-24          [-1, 128, 27, 27]           8,192\n      BatchNorm2d-25          [-1, 128, 27, 27]             256\n             ReLU-26          [-1, 128, 27, 27]               0\n       BasicBlock-27          [-1, 128, 27, 27]               0\n           Conv2d-28          [-1, 128, 27, 27]         147,456\n      BatchNorm2d-29          [-1, 128, 27, 27]             256\n             ReLU-30          [-1, 128, 27, 27]               0\n           Conv2d-31          [-1, 128, 27, 27]         147,456\n      BatchNorm2d-32          [-1, 128, 27, 27]             256\n             ReLU-33          [-1, 128, 27, 27]               0\n       BasicBlock-34          [-1, 128, 27, 27]               0\n           Conv2d-35          [-1, 256, 14, 14]         294,912\n      BatchNorm2d-36          [-1, 256, 14, 14]             512\n             ReLU-37          [-1, 256, 14, 14]               0\n           Conv2d-38          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-39          [-1, 256, 14, 14]             512\n           Conv2d-40          [-1, 256, 14, 14]          32,768\n      BatchNorm2d-41          [-1, 256, 14, 14]             512\n             ReLU-42          [-1, 256, 14, 14]               0\n       BasicBlock-43          [-1, 256, 14, 14]               0\n           Conv2d-44          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-45          [-1, 256, 14, 14]             512\n             ReLU-46          [-1, 256, 14, 14]               0\n           Conv2d-47          [-1, 256, 14, 14]         589,824\n      BatchNorm2d-48          [-1, 256, 14, 14]             512\n             ReLU-49          [-1, 256, 14, 14]               0\n       BasicBlock-50          [-1, 256, 14, 14]               0\n           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n             ReLU-53            [-1, 512, 7, 7]               0\n           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n           Conv2d-56            [-1, 512, 7, 7]         131,072\n      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n             ReLU-58            [-1, 512, 7, 7]               0\n       BasicBlock-59            [-1, 512, 7, 7]               0\n           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n             ReLU-62            [-1, 512, 7, 7]               0\n           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n             ReLU-65            [-1, 512, 7, 7]               0\n       BasicBlock-66            [-1, 512, 7, 7]               0\nAdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n================================================================\nTotal params: 11,176,512\nTrainable params: 0\nNon-trainable params: 11,176,512\n----------------------------------------------------------------\nInput size (MB): 0.52\nForward/backward pass size (MB): 58.71\nParams size (MB): 42.64\nEstimated Total Size (MB): 101.87\n----------------------------------------------------------------\n"
    }
   ],
   "source": [
    "modules=list(model.children())[:-1]\n",
    "model=nn.Sequential(*modules)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.to(config.device)\n",
    "\n",
    "summary(model, input_size=(3, 214, 214))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = transforms.Scale((224,224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(image_name):\n",
    "    # 1. Load the image with Pillow library\n",
    "    img = Image.open(image_name)\n",
    "\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    \n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)\n",
    "    \n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data)\n",
    "    \n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    \n",
    "    # 6. Run the model on our transformed image\n",
    "    model(t_img)\n",
    "    \n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "    \n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}